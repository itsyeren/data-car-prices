## ğŸš— Car Prices

### ğŸ¯ Objective
- Prepare the dataset for modeling
- Apply feature selection to identify the most informative variables
- Classify cars as **cheap** or **expensive**

### ğŸ§¹ Data Cleaning
- Removed **14 duplicate rows**
- Handled missing values:
  - `carwidth` â†’ mean imputation (after replacing `*` with NaN)
  - `enginelocation` â†’ most frequent value

### ğŸ“ Feature Scaling
- `carwidth`, `stroke`, `peakrpm` â†’ RobustScaler
- `curbweight` â†’ StandardScaler
- `cylindernumber` â†’ mapped to numeric values and scaled

### ğŸ”¤ Feature Encoding
- `aspiration`, `enginelocation` â†’ One-Hot Encoding (binary)
- `enginetype` â†’ One-Hot Encoding (multi-class)
- `price` â†’ Label Encoding (`0 = cheap`, `1 = expensive`)

### ğŸ¤– Base Model
- Model: Logistic Regression
- Evaluation: Cross-Validation
- Base model accuracy: **~0.88**

### ğŸ” Feature Selection
- Method: Permutation Importance
- Weak features removed (importance â‰¤ 0.05)
- Strong features identified:
  - `carwidth`
  - `curbweight`

### ğŸ“ˆ Final Model Performance
- Accuracy before feature selection: **~0.85**
- Accuracy after feature selection: **~0.90**

### âš–ï¸ Stratification
- Used stratified splitting to preserve class distribution
- Applied `stratify=y` in train-test split
- Demonstrated stratification with `StratifiedKFold`
